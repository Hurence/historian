=== Installation mono noeud de production

==== Pre-requis pour une installation mono serveur en production

La configuration minimale du serveur pour une installation mono serveur (en production) du data historian est:

- un OS CentOS ou Redhat 7.x
- 32 Gigabits de RAM
- 32 vcores de CPU
- 2 Tera octets de disque
- Java 8
- Spark 2.3.4
- Solr 8.2.0
- Grafana 7.0.3

Dans cette section nous avons prévu des petits guides pour vous aider a installer solr 8.2.0, spark 2.3.4 et grafana 7.0.3.
Mais nous recommandons de vous référer à la documentation officiel pour des installations de production.
Si vous avez déjà des serveurs existants vous pouvez directement passer à cette <<install-production-hurence-datasource-grafana-plugin,section>>


==== Installation de Apache SolR

Apache SolR est la base de donnée utilisé par l'historian, elle peut être remplacée par un autre moteur de recherche.

Vous pouvez télécharger la version 8.2.0 de solr sur le lien suivant : https://archive.apache.org/dist/lucene/solr/8.2.0/solr-8.2.0.tgz[solr-8.2.0.tgz]
ou via le https://lucene.apache.org/solr[site officiel]. Nous vous invitons également a suivre la documentation officiel
pour installer un cluster solr de production.

Vérifiez que votre instance solr fonctionne correctement en allant sur l'interface graphique à l'adresse suivante :
"http://<solrhost>:8983/solr/#/~cloud"

==== Install Apache Spark

Pour installer spark vous pouvez téléchargez cette archive :
https://archive.apache.org/dist/spark/spark-2.3.4/spark-2.3.4-bin-without-hadoop.tgz[spark-2.3.4-bin-without-hadoop.tgz]

Les commandes suivantes vous permettront d'avoir une installation locale. Sinon veuillez suuivre les indications officiels
pour un cluster de production.

[source,bash]
----
# get Apache Spark 2.3.4 and unpack it
cd $HDH_HOME
wget https://archive.apache.org/dist/spark/spark-2.3.4/spark-2.3.4-bin-without-hadoop.tgz
tar -xvf spark-2.3.4-bin-without-hadoop.tgz
rm spark-2.3.4-bin-without-hadoop.tgz

# add two additional jars to spark to handle our framework
wget -O spark-solr-3.6.6-shaded.jar https://search.maven.org/remotecontent?filepath=com/lucidworks/spark/spark-solr/3.6.6/spark-solr-3.6.6-shaded.jar
mv spark-solr-3.6.6-shaded.jar $HDH_HOME/spark-2.3.4-bin-without-hadoop/jars/
cp $HDH_HOME/historian-1.3.4-SNAPSHOT/lib/loader-1.3.4-SNAPSHOT.jar $HDH_HOME/spark-2.3.4-bin-without-hadoop/jars/
----

==== Installation de Grafana

Installez Grafana pour votre plateforme comme décrit ici : `https://grafana.com/docs/grafana/latest/installation/requirements/`.
Une fois l'installation de votre cluster grafana effectué nous allons passer à l'installation de notre plugin grafana datasource
nécessaire pour consulter des dashboard basé sur notre historian.

[[install-production-hurence-datasource-grafana-plugin]]
===== Installation Plugin Grafana pour utiliser le data historian Hurence

Pour consulter les données de l'historian via des dashboard nous utilisons grafana. Dans ce but nous avons développer
nos propres plugins grafana que nous ferons évoluer avec l'historian.

Pour installer le plugin datasource suivez les https://github.com/Hurence/grafana-historian-datasource#installation[instruction sur le projet correspondant]

TODO pointer sur une release !


==== Installation de l'historian

Hurence Data Historian est composé de scripts et fichiers binaires qui permettent de travailler avec les timeseries
et les chunks. Téléchargez la dernière version de l'historian à l'adresse suivante
https://github.com/Hurence/historian/releases/download/v1.3.4/historian-1.3.4-SNAPSHOT.tgz[historian-1.3.4-SNAPSHOT.tgz]
Décompressez l'archive et entrez dedans, ensuite commencez l'installation en tapant la commande suivante :

[source,bash]
----
sudo ./bin/install.sh
----

Il sera alors demander à l'utilisateur plusieurs informations.

Voici un exemple :

image::../../../resources/images/screenshot_install_mono_noeud.png[]

Dans la suite, on appellera le chemin indiqué pour l'installation de l'historian '$HDH_HOME'.

A l'issue de ce script, vous aurez :

* l'historian installer au chemin indiqué $HDH_HOME.
* Le plugin https://github.com/Hurence/grafana-historian-datasource[datasource grafana de l'historian]
installé sur le serveur grafana indiqué lors de l'installation


Voici la structure de $HDH_HOME a l'issue de l'installation par défaut :
* $HDH_HOME/bin/historian-server.sh : Permet de lancer et arrêter l'api REST de l'historian.
* $HDH_HOME/conf/log4j.properties : Fichier pour contrôler le niveau des logs en mode production (défaut).
* $HDH_HOME/conf/log4j-debug.properties : Fichier pour contrôler le niveau des logs en mode debug.
* $HDH_HOME/conf/historian-server-conf.json : Le fichier de configuration du serveur fournissant l'api rest de l'historian.

Le script $HDH_HOME/bin/historian-server.sh sert à lancer/arrêter l'api rest de l'historian.

Pour lancer l'historian taper la commande suivante :

[source,bash]
----
./bin/historian-server.sh start
----

Pour arrêter l'historian taper la commande suivante :

[source,bash]
----
./bin/historian-server.sh stop
----

Attention ces commandes n'affectent ni grafana ni solr qui sont des services indépendants.

===== Description du fichier de configuration de l'historian

include::./_description_conf_file.ad[]

Generation un fichier de configuration pendant le script d'install selon les informations renseignées