=== Installation mono noeud de production

==== Pre-requis pour une installation mono serveur en production

La configuration minimale du serveur pour une installation mono serveur (en production) du data historian est:

- un OS CentOS ou Redhat 7.x
- 32 Gigabits de RAM
- 32 vcores de CPU
- 2 Tera octets de disque
- Java 8
- Spark 2.3.4
- Solr {solr_version}
- Grafana 7.0.3

Dans cette section nous avons prévu des petits guides pour vous aider a installer solr {solr_version}, spark {spark_version} et grafana {grafana_version}.
Mais nous recommandons de vous référer à la documentation officielle de ces outils pour des installations de production.
Si vous avez déjà des serveurs existants vous pouvez directement passer à cette <<install-production-hurence-datasource-grafana-plugin,section>>


==== Installation de Apache SolR

Apache SolR est la base de donnée utilisée par l'historian, elle peut être remplacée par un autre moteur de recherche.

Vous pouvez télécharger la version {solr_version} de solr sur le lien suivant : https://archive.apache.org/dist/lucene/solr/{solr_version}/solr-{solr_version}.tgz[solr-{solr_version}.tgz]
ou via le https://lucene.apache.org/solr[site officiel]. Nous vous invitons également à suivre la documentation officielle
pour installer un cluster solr de production.

Vérifiez que votre instance solr fonctionne correctement en allant sur l'interface graphique à l'adresse suivante :
"http://<solrhost>:8983/solr/#/~cloud"

==== Install Apache Spark

Pour installer spark vous pouvez télécharger cette archive :
https://archive.apache.org/dist/spark/spark-{spark_version}/spark-{spark_version}-bin-without-hadoop.tgz[spark-{spark_version}-bin-without-hadoop.tgz]

Les commandes suivantes vous permettront d'avoir une installation locale. Sinon veuillez suuivre les indications officiels
pour un cluster de production.

[source,bash]
----
# get Apache Spark 2.3.4 and unpack it
cd $HDH_HOME
wget https://archive.apache.org/dist/spark/spark-{spark_version}/spark-{spark_version}-bin-without-hadoop.tgz
tar -xvf spark-{spark_version}-bin-without-hadoop.tgz
rm spark-{spark_version}-bin-without-hadoop.tgz

# add two additional jars to spark to handle our framework
wget -O spark-solr-3.6.6-shaded.jar https://search.maven.org/remotecontent?filepath=com/lucidworks/spark/spark-solr/3.6.6/spark-solr-3.6.6-shaded.jar
mv spark-solr-3.6.6-shaded.jar $HDH_HOME/spark-{spark_version}-bin-without-hadoop/jars/
cp $HDH_HOME/historian-1.3.4-SNAPSHOT/lib/loader-1.3.4-SNAPSHOT.jar $HDH_HOME/spark-{spark_version}-bin-without-hadoop/jars/
----

==== Installation de Grafana

Installez Grafana pour votre plateforme comme décrit ici : `https://grafana.com/docs/grafana/latest/installation/requirements/`.
Une fois l'installation de votre cluster grafana effectuée nous allons passer à l'installation de notre plugin grafana datasource
nécessaire pour consulter des dashboard basés sur notre historian.

Il est nécessaire d'avoir au minimum la version 7.0.3 de Grafana.

[[install-production-hurence-datasource-grafana-plugin]]
===== Installation Plugin Grafana pour utiliser le data historian Hurence

Pour consulter les données de l'historian via des dashboard nous utilisons Grafana. Dans ce but nous avons développé
nos propres plugins Grafana que nous ferons évoluer avec l'historian.

Pour installer le plugin datasource suivez les https://github.com/Hurence/grafana-historian-datasource#installation[instruction sur le projet correspondant]



==== Installation de l'historian

Hurence Data Historian est composé de scripts et fichiers binaires qui permettent de travailler avec les time series
et les chunks. Téléchargez le script dinstallation de l'historian pour votre version
https://github.com/Hurence/historian/releases/download/v1.3.5/install.sh[install.sh].
Lancez l'installation en lançant ce script :

NOTE:: Solr n'aime pas pour des questions de sécurité que vous installiez et lanciez en root.
Utilisez donc un utilisateur qui n'est ni sudoer ni root (un utilisateur applicatif ou le vôtre) mais vérifiez bien que vous avez les droits en  écriture là où HDH va s'installer (par défaut /opt/hdh).

[source,bash]
----
bash ./install.sh
----

NOTE:: le script install.sh doit être exécutable. Si vous obtenez un problème d'autorisation au lancement, vérifiez qu'il a les bonnes propriétés et sinon exécutez cette commande:

[source,bash]
----
chmod +x install.sh
----

NOTE:: lors de l'installation Solr vous met en garde éventuellement sur votre configuration machine en ce qui concerne le nombre de fichiers ouverts qui est généralement réduit à 1024. Si vous voulez une installation robuste pour accueillir de nombreuses données il vous faudra changer ce paramètre avec la commande ulimit (et l'édition d'un fichier de configuration dont le nom dépend de votre OS).
Référez vous à votre documentation système.

Il sera alors demandé à l'utilisateur plusieurs informations.

Voici un exemple :

image::screenshot_install_mono_noeud.png[]

Dans la suite, on appellera le chemin indiqué pour l'installation de l'historian '$HDH_HOME'.

A l'issue de ce script, vous aurez :

* l'historian installé au chemin indiqué $HDH_HOME.
* Le plugin https://github.com/Hurence/grafana-historian-datasource[datasource grafana de l'historian]
installé sur le serveur Grafana indiqué lors de l'installation


Voici la structure de $HDH_HOME à l'issue de l'installation par défaut :
* $HDH_HOME/bin/historian-server.sh : Permet de lancer et arrêter l'api REST de l'historian.
* $HDH_HOME/conf/log4j.properties : Fichier pour contrôler le niveau des logs en mode production (défaut).
* $HDH_HOME/conf/log4j-debug.properties : Fichier pour contrôler le niveau des logs en mode debug.
* $HDH_HOME/conf/historian-server-conf.json : Le fichier de configuration du serveur fournissant l'api rest de l'historian.

Le script $HDH_HOME/bin/historian-server.sh sert à lancer/arrêter l'api rest de l'historian.


Vous pouvez vérifier que votre serveur a bien été lancé avec la commande suivante:

[source,bash]
----
curl http://localhost:8080/api/grafana/v0
[source,bash]
----

Si ce n'est pas le cas, allez voir les logs (dans la directory d'installation et la sous directory historian-${version}, il y a un fichier app.log). En général ce sera un problème de droits pour créer des directories: notamment dans /tmp (vérifiez bien vos droits en écriture sur cette directory).


Pour lancer ou relancer l'historian taper la commande suivante :

[source,bash]
----
./bin/historian-server.sh start
(ou ./bin/historian-server.sh restart)
----

Pour arrêter l'historian taper la commande suivante :

[source,bash]
----
./bin/historian-server.sh stop
----

Attention ces commandes n'affectent ni Grafana ni Solr qui sont des services indépendants.

===== Description du fichier de configuration de l'historian

include::./_description_conf_file.ad[]

Generation un fichier de configuration pendant le script d'install selon les informations renseignées