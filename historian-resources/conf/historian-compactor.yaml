solr:
  # ZK connect string. Comma separated host:port pairs, each corresponding to a zk server. e.g.
  # "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002" If the optional chroot suffix is used the example would look like:
  # "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002/app/a" where the client would be rooted at "/app/a" and all paths
  # would be relative to this root - ie getting/setting/etc..."/foo/bar" would result in operations being run on
  # "/app/a/foo/bar" (from the server perspective).
  zkHost: zookeeper:2181
  collection: historian

spark:
  # Any entry under the spark entry is expected to match the spark application configuration
  # specified at https://spark.apache.org/docs/latest/configuration.html#application-properties
  # including the "spark." prefix.
  appName: HistorianCompactor
  master: yarn
  deployMode: client
  numExecutors: "2"
  driverCores: "1"
  driverMemory: "512m"
  executorCores: "1"
  executorMemory: "512m"

compaction:
  scheduling:
    # Period at which the compaction algorithm is launched in seconds
    # If an algorithm run takes longer than this time to run, a second run will not be launched while
    # the first has not completed. If the algorithm run takes less time than the period to run, the next
    # algorithm run will be at [start time of first run + period].
    period: 10
    # Should the first algorithm run occur as soon as the compactor starts, or should it wait for the next period
    # before running for the first time? Defaults to true.
    startNow: true
    date.bucket.format: yyyy-MM-dd