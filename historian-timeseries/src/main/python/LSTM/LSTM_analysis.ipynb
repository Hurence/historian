{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f07aaa-af16-4d3c-a74b-8cc5eb6a28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('../data/it-data-4metrics.csv', sep=',')\n",
    "data = read_csv('LSTM_id2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029d4274-3dec-40d8-9d26-b4689927e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.iloc[:,0:4]\n",
    "# indexNames = dataframe[ dataframe['metric_id'] == dataframe.iloc[95744,0] ].index\n",
    "# indexNames = dataframe[ dataframe['metric_id'] == dataframe.iloc[117264,0] ].index\n",
    "# indexNames = dataframe[ dataframe['metric_id'] == data.iloc[70,1] ].index\n",
    "# indexNames = dataframe[ dataframe['metric_id'] == dataframe.iloc[243333,0] ].index\n",
    "indexNames = dataframe[ dataframe['metric_id'] == dataframe.iloc[0,0] ].index\n",
    "\n",
    "dataframe = dataframe.iloc[indexNames].sort_values(by='timestamp', ascending=True).loc[:,['value']]\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b817a752-1afd-4f84-9a28-858cd9e8130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdca8f7-ce61-46d0-ba93-2740c1c6a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719a8f64-14c2-4cd1-ae05-acaa85e2cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 30\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_valid, y_valid = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff40045-18b2-4aee-bc70-4c1a3122155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[28.125 29.625 44.375 ... 13.75  15.375 13.5  ]]\n",
      "\n",
      " [[29.625 44.375 16.875 ... 15.375 13.5   13.75 ]]\n",
      "\n",
      " [[44.375 16.875 17.875 ... 13.5   13.75  16.125]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[15.625 18.375 16.75  ...  2.25   2.125 13.75 ]]\n",
      "\n",
      " [[18.375 16.75  16.5   ...  2.125 13.75  13.5  ]]\n",
      "\n",
      " [[16.75  16.5   27.    ... 13.75  13.5   13.375]]]\n",
      "[13.75  16.125 14.25  14.125 14.375 15.75  15.    15.    15.125 17.\n",
      " 18.625 15.375 14.5   14.25  15.125 18.125 16.25  14.375 16.375 14.625\n",
      " 16.25  15.    15.    14.375 15.75  15.625 16.125 14.5   14.25  15.125\n",
      " 12.75   6.5   11.5    7.375  8.125  7.375  8.5    5.375  9.875  8.75\n",
      "  6.75   7.75   6.75  13.     7.875  6.625  7.375 10.375  9.875  9.625\n",
      "  7.5   12.625  7.5   12.75   8.    10.625 10.875  9.375  9.125  9.875\n",
      "  9.75  13.5    8.5    5.25  10.375 11.     8.5    7.5    7.5    9.25\n",
      " 12.5    8.     9.75   8.25   6.625 11.375  7.75   9.375 10.125 10.\n",
      " 12.625 13.625  9.125 14.625 10.5   12.625  8.875 22.    14.375 11.125\n",
      "  9.375 11.    10.5   10.875  9.75  14.25  12.75  12.    11.375 17.\n",
      "  9.5   14.125 15.625  9.375 11.875 11.125  8.875 10.75  10.125 14.875\n",
      " 11.125 14.875  7.875 12.5   11.875 11.375  9.5   14.875 11.25  14.375\n",
      " 13.625 14.625 13.625 10.875 13.25  16.75  19.125 15.75  11.375 16.125\n",
      " 14.25  12.625 15.125 11.5   14.25  17.75  11.75  10.25  12.25  13.75\n",
      " 11.    15.25  16.25  16.125 12.125  8.5    9.875 14.875 11.125 20.375\n",
      " 14.75  11.75  11.25  13.125 11.875 19.875 14.    11.375 12.375 18.\n",
      " 12.375 13.375 14.625 11.    17.    15.5   10.375 10.625 15.625 12.875\n",
      " 16.125 17.25  11.375 14.25  12.125 13.    12.625 13.25  13.125 16.125\n",
      " 14.875 20.125 15.625 14.125 11.5   12.75  11.125 15.875 17.5   19.875\n",
      " 14.5   13.375 11.25  15.375 13.25  16.25  10.625 10.375 10.625 16.25\n",
      " 18.    13.125 15.875 18.375 12.5   14.625 24.5   19.75  16.125 14.5\n",
      "  8.5   10.625 14.875 17.625 12.5   14.625 17.25  16.75  18.125 16.\n",
      " 19.625 16.    15.125  9.75  12.125 15.5   22.875 15.5   16.25  16.875\n",
      " 19.375 16.625  8.25   8.875 10.875  3.25   3.875  3.875  4.     4.625\n",
      "  3.75   3.875  4.     4.75   5.5   13.875 15.    17.25  17.5   19.25\n",
      " 18.25  18.5   16.75  18.875 19.    20.125 17.25  35.125 26.75  17.5\n",
      " 18.75  16.625 19.875 22.375 11.875 12.625  6.625  9.375  9.5    6.75\n",
      "  7.25   7.5   11.75  11.25   7.     5.375  9.     9.     5.875  8.125\n",
      "  6.     9.    14.25  15.125 15.5   12.75   5.875  8.25   6.375  9.25\n",
      "  7.5    8.     9.5   11.75   7.75   8.5   14.875 15.    15.25  17.\n",
      " 16.5   14.625 17.    17.    15.25  16.125 16.5   16.25  14.5   17.375\n",
      " 20.625 18.75   6.75   8.625  7.125 12.875  7.875 11.     7.125  8.5\n",
      "  6.25  10.875  6.125 11.625 11.625 12.625 11.75   9.875 10.75   8.\n",
      "  7.5   13.25  16.625 14.125  6.375 10.125  9.25  10.625 14.25  14.375\n",
      "  7.625  8.625  8.    14.75   6.75  13.875 10.875 13.75   8.     9.625\n",
      "  7.5    9.75  10.375 17.5   10.25  12.25  12.125 15.375  9.875 13.\n",
      "  9.875 13.75   9.5   12.375  9.25  11.125  8.125 12.625 13.875 13.5\n",
      " 13.75  14.625 12.    13.875 10.875 14.    11.5   13.5   12.5   14.375\n",
      " 12.375 19.375 10.125 10.75   9.5   13.375 13.     9.75  12.25  13.75\n",
      " 11.875 14.25  11.75  16.375 15.    18.75  11.625  9.875 11.25  13.75\n",
      " 13.    14.625 13.75  11.5    7.    15.875  8.25  15.625 14.375 12.625\n",
      " 14.125 13.5    8.875 13.75  10.875 12.5    9.    14.125 13.25  12.375\n",
      " 13.25  12.875  8.875 13.125 10.25  12.    11.5   15.5    8.75  17.125\n",
      "  7.25  13.    10.625 10.125 12.    16.     6.75  15.875 10.625 15.\n",
      " 10.625 13.375  9.    15.25  12.25  15.875 11.625 18.125 10.5   14.\n",
      " 11.625 13.    13.875 16.25  13.5   11.875 12.5   12.625 13.    15.75\n",
      " 12.25  15.875 14.25  18.75   8.875 17.625 10.75  13.125 17.    11.\n",
      "  8.875 15.75  13.75  12.875 15.625 14.125  9.875 12.875 10.    13.\n",
      " 14.    14.     9.625 13.375 15.75   7.625 15.25  13.875  9.875 19.875\n",
      " 11.25  34.25  17.25  14.5   14.625 18.875 16.125 15.625 18.375 16.75\n",
      " 16.5   27.    19.    16.625 13.375 18.    16.125 25.625 10.25   8.75\n",
      " 34.25  14.25  12.    20.    14.375 17.875 18.125 24.    18.75  18.5\n",
      " 15.375 17.375  8.5    1.875  2.25   2.125 13.75  13.5   13.375 13.5  ]\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_valid = np.reshape(x_valid, (x_valid.shape[0], 1, x_valid.shape[1]))\n",
    "print(x_valid)\n",
    "print(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a97de82-3bc3-410e-bd56-615d0bb2dba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8003d7340>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379690f9-6743-4b90-a79b-0801539c34eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3af447cf5c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# invert predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtestPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict = model.predict(x_valid)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "y_train = scaler.inverse_transform([y_train])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "y_valid = scaler.inverse_transform([y_valid])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_valid[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "testScore = mean_squared_error(y_valid[0], testPredict[:,0], squared=False)\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a744a-4d7e-4c81-a4c3-2eee4c069c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "plt.figure(figsize=(18,4))\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
